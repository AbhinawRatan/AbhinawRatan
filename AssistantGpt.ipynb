{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiWmcKCWhxqsZ1Z+K9JcqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinawRatan/AbhinawRatan/blob/main/AssistantGpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`Installation`** "
      ],
      "metadata": {
        "id": "90X8_PPH6Trp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxdXSg4s6Nut",
        "outputId": "07e5885e-b4dc-4f21-fc7c-2629c9b181d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 11.6 MB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 278 kB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 79.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 78.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 11.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 64.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 593 kB 72.0 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-26xcypvh\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-26xcypvh\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.7 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 76.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=c54234ebc8938655e04cd8a71c390869d9c14c7b10c0e735b0fd4b8f6ec0bf2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dwbhknf9/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1 whisper-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio\n",
        "!pip install -q pyChatGPT\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install -q gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code**"
      ],
      "metadata": {
        "id": "OKSnufWD7uZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "import time\n",
        "from pyChatGPT import ChatGPT\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "secret_token = \"eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..8yZoMf1YgS3aY0Uh.4lbuueN3tggltftJ8SsiURFrXPT0DflpVWlgqiVJq1jZK8yFl8ZeDVNHlsuQvOueMsEg43DNvFVNJS4t-ulORKUDan85fLhsFSokDF6LoIKIam56DwtPSZwvQyWVldwBud5cerFkuDFx-sC5onvnJj1hf-swhpLZH25AajSIwbu4ZPMhwEiL0ohAtPMFV_11AmVwzMDFZ27E5o9CzVcx8xVQHHoo28n3OZIxGHJZ96LkddrsnF5c3e-AIp-z5Y9_IaDHL8pSaORytkWjNR648vobqp1DDE-jK-vE1GBFBv_B26Q-ADsN1_ObczjKWH-NpwNRs719vfG3dfXMAsNbal4pULBYPSu6VL0ls7YGFKm4YsRdoJxpvFGBXpkr2Wsq2HR8mGjaoxm8gZpAlkK1wj8-V4PK3LUPmRd7nekBTyl6nGxMzkgUetjIXJIbeeulQUNmSct2BjofzDIt8WZO31LHiCPWzzisbm36KHvXVEh4HtotZga5TzEdXaPe5TyYbvVaxzOtA1Zto15XxHu8uLFKQQKA-Luu0FnFjk-RYAGvD1lGMOlnhC2hciFu_cuBVYRB2Li8HYGAJSJ8cF3JCNvSAdhN4uTjlXVsIBYzQLiA_0BiYaLIGFzqwYcTgbxmkBiyx3d__R8KneI_Uqure0YZLIDW4DECkq_i4I496rwMTIyY-k1-8HZDOriswMmye4R3bfuOy8NceVpNZ_BvcL1x6kg_ZHC598WOVq3CUGoSTody5lpxm6ouTrokRiaVdPkcLYwdE35qYk7kAGYXMw_fzXgNhQyFcmM2YreO6pXPrGZr723GaGi1omV3ti0HlZTZBh77VcdRaZberm5nVrnk2CkXYJqt4tQAoIWW5PEKJlXxFAVqH8i8swuXvk2f3_uStHr1etZJdfoNPAklIS-TES4R92khv-nsPnGKAN8RCQ3kqEAQkI-F-2Cz9ezithbXASm_NCM7PkMJnns3de5gJgVjrH_LqVTo-vLiND85q29sIDI-1np6TUu6SCadT4Sz7gxgkxJ4SBDlne6eh3kr8PI0_Tj_u38Hm8z0gHirN4o_r2mC_nRyn5yFdltfqsPeSoSoIw8ud1QSJ2WPIBAWkfXg-tFgrVkdkZomW7vF4S4EZpF1Tt-TNWu9n1KLssH82DlDOLVJ89Hg5RLcqYPy4UTBw-h5iQjoycwH2AFGRHC5mXsZfVu0WTkB2d7sN5K335IGYaHzBBQEjvp0sv4MfrmG9zA_SpK8G5-ERU474ET-ZOhIGNiw0BPS_PSkcUBAFNeKlYS_hY8-j0Owjl688G1k2jScZOfYGkBkcIyBnrkQkmoM4OerlwmdCYI527TUdO1WyylerJkhDpqEN_wL0nlC9HDv1RmTB_lFCK9QI7cR8tC1ffi5_3dMyb0OEqJQi3WyO3VWdR5Fu5nXvTKKDAXmowzEIrpTUKBU9fDoORGlzmn6kMH1PE0HiqKtLdrvodlWtahWnOLT-NzUG3mryu6o7IlADLEUTocp7oHIiNE9u9soFvhX6y4Z3Dl4FUdowfH1E3aXNjQe2PvqUsHdnnASm86PVqFj4A4ZC6kxygKBd_LzJvU-j3cSqmCxeMp5NPPmieALXMNMgm0MF8IC1KQ2257VLYcBnFtyElxcIRL7jcx-gLs0EiNkdTBFLkaB9hyjd2a0JbMKlfBYgbSEGJpC03-QfakPDTb9xQq9rR_XH_6FjP_DY2i9MSC9qTKFH0blstQZO0C0xET5e9eL5NvFuRmJokTjNzTzz3a9O3JBgXrtxBJLDJMfky7-cxFYFvsSriwVYOCiBvJnGiu4fV-qUUry2I86dVH5iafqMFLcEqzTglX_Kz7s4wdt81PpzzaCh5pZWa46vnje8PIhF-_jHcykc-fXv1ousRwOaOmQ7as-6gnpYYLLebLc-GspFeHNXy3fRqc2seGDCr6Lnd5X_emXORaqZTNabe3zB1LkozSIQzoZXlXyoWfrGtJTayKfIVeK1ibHwKPkYWDY3PTAQLEW9bcft5H3OOj8PrjUTMKsVHKwf6iIe94KHBgNIkxYtxeCZs5iujySZVWh1_r_UkVBso4PvJ2wSE-sRNRk347lpuQk1hBI1Z3GgMOXQNNDWJtN2v8TWSrUMKwEj15PvFdxj4UHQ3NaPErdN8UdK6a_JemCaYm3FGBME76VN6SJI6TNvVRT-p4M2dOFdkzhAJDLeufZa59cuqnAJgyfCNc_Oz80LvzlEhKMH4VNDwlglwiP4eWjoQY-rAg.k_S0D-pcHtT6M6QFaXy9wQ\"\n",
        "model = whisper.load_model(\"base\")\n",
        "model.device\n",
        "def transcribe(audio):\n",
        "\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    result_text = result.text\n",
        "\n",
        "    # Pass the generated text to Audio\n",
        "    chatgpt_api = ChatGPT(secret_token)\n",
        "    resp = chatgpt_api.send_message(result_text)\n",
        "    out_result = resp['message']\n",
        "\n",
        "    return [result_text, out_result]"
      ],
      "metadata": {
        "id": "z5BVXcy3703X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5585a0-e3c5-4728-e4ce-25f181b6057e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 140MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI\n"
      ],
      "metadata": {
        "id": "BD44-GJlA8Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_1 = gr.Textbox(label=\"Speech to Text\")\n",
        "output_2 = gr.Textbox(label=\"ChatGPT Output\")\n",
        "\n",
        "\n",
        "gr.Interface(\n",
        "    title = 'Welcome to the GPT Assistant_by Abhinaw Ratan', \n",
        "    fn=transcribe, \n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "\n",
        "    outputs=[\n",
        "        output_1,  output_2\n",
        "    ],\n",
        "    live=True).launch( share=True )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "6-f7xvXUA7Gr",
        "outputId": "2fe60312-f55d-438c-c78e-5c8b7da25440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hint: Set streaming=True for Audio component to use live streaming.\n",
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://ab9ba6892f224b7e.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ab9ba6892f224b7e.gradio.app\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}